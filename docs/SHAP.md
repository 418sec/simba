# Model explainability and calculating feature SHAP values in SimBA

<p align="center">
<img src="https://github.com/sgoldenlab/simba/blob/master/images/SHAP0.png" />
</p>



An understanding, and ability to explain and communicate, how and why machine learning models reach their different decisions, is important not only for the scientific method, but will help you compare the similarities and differences of disperate classifiers that has been generated by different annotators and institutions. Machine learning explainability metrics could help you answer questions like:

* Why does my classifier think some specific frames are attack events, while it think other frames are non-attack events?
 
* Why does my tracking model think this is the nose of the animal?
 
* Why does the classifier generated by annotator X classify events so differently (or similarly) relative to the classifier generated by person Y? 

* Which, of several classifiers, classify events the way I as a human observer would classify the same events?
 
Explainability metrics are **extremely** important, as it is possible that the classifiers you are using *appear* to look for the same behavioral target behaviours and features as a human observer would (have strong *face validity*) while the classifier in fact looks as something very different from the human observer (weak *construct validity*). These weaknesses are typically revealed in new videos and recording environments that were absent in the classification training data set. 

In this tutorial we will look at how we can use [SHAP (SHapley Additive exPlanations)](https://github.com/slundberg/shap) within SimBA to calculate how much each feature contributes to the final behavioral classification score for each frame. Through this method we will get an verbalizable explanation for the classification score for each frame, such as: 

*Frame N on Video X was was classified as containing attack behavior mainly because of the small distance between animal A and B and that the movements of animal A was large. The movement of the animals increased the atatck certainty with 30%, and the distance between them increased the atatck certainty with a further 80%*. 
 
 
In brief, when using SHAP, each feature is evaluated independently, and the final classification probability is distributed among the individual features according to their contribution, as evaluated after permutations within the order of feature-introductions into the classification scenario:

<p align="center">
<img src="https://github.com/sgoldenlab/simba/blob/master/images/SHAP1.png" />
</p>

Where the *base probability* in the figure above, is the probability if picking a frame that contains your behavior by chance (e.g., if half of your video frames contain attack events, then the base probability will be 50%). To read more about SHAP values, see the [SHAP GitHub repository](https://github.com/slundberg/shap) which SimBA wraps, or read the excellent [SHAP paper in nature machine learning intelligence](https://www.nature.com/articles/s42256-019-0138-9). 

## Part 1: Generate a dataset

SimBA calculates SHAP values for the classifier at the same time as the model is being trained. Thus, before analysing SHAP scores, we need a dataset that contains behavioral annotatiopns. Therefore, you will need complete the steps detailed in the [Scenario 1 tutorial](https://github.com/sgoldenlab/simba/blob/master/docs/Scenario1.md) **Part 1 Step 1** to **Part 2 Step 6**. That is, you will need to complete everything from [Creating a project](https://github.com/sgoldenlab/simba/blob/master/docs/Scenario1.md#part-1-create-a-new-project-1) up to, and including [labelling behavioral events](https://github.com/sgoldenlab/simba/blob/master/docs/Scenario1.md#step-6-label-behavior-ie-create-annotations-for-predictive-classifiers). 

>Note: If you already have annotations generated elsewhere (e.g., downloaded from the [SimBA OSF repository](https://osf.io/d69jt/), you may not have to go through **Part 1 Step 1** to **Part 2 Step 6** as detailed above. When calculating the SHAP values, SiMBA will loook inside your `project_folder/csv/targets_inserted` subdirectory for annotated files (just as SimBA does when generating the classifier). The important thing is that this folder is populated with files containing behavioral annotations. 

## Part 2: Compute SHAP scores

### Step 1: Define SHAP settings
Next, navigate to the `Train machine model` tab and click on `Settings`. In the pop-up window, fill out your model `hyperparameter` settings as described [HERE]
(https://github.com/sgoldenlab/simba/blob/master/docs/Scenario1.md#step-7-train-machine-model. At the bottom of the `Settings` pop up window, you will see these entry boxes. Tick the `Calculate SHAP values` entry box to enable them:

<p align="center">
<img src="https://github.com/sgoldenlab/simba/blob/master/images/SHAP2.png" />
</p>

If this box is ticked, and the entry boxes are filled in, SiMBA will also calculate SHAP values while generating your behavioral classifier. SimBA will use your annotations when doing so. SHAP calculations are an computationally expensive process, so we most likely can't use **all** of your annotations to calculate them. The time it takes to calculate SHAP scores for a single frame will depend on how many features you have the the specs of the computer you are using, but in all likelihood it will take **several seconds, and possibly tens of seconds**, for a single frame. We therefore have to select a sub-set of frames that we will calculate SHAP scores for. 

  - In the `# target present` entry box, enter the number of frames (integer - e.g., `100`) with the behavioral target **present** to calculate SHAP values for. 
  - In the `# target absent` entry box, enter the number of frames (integer - e.g., `100`) with the behavioral target **absent** to calculate SHAP values for.
  
Once you have filled in the SHAP entry boxes, click on either `save settings into global environment` or `save settings for specific model`, depening on wether you are generating one model, or several models at once. For more information on generating one vs several models, click [HERE](https://github.com/sgoldenlab/simba/blob/master/docs/Scenario1.md#train-predictive-classifiers-start-the-machine-training). 

Click to close the `Settings` pop-up window. 

### Step 2: Train machine model and and generate your SHAP values.

To start training by clicking on `Train single model from global environment` or `Train multiple models, one for each saved settings`. You will be able to follow the progress in the Terminal window. A new message will be printed in the main SimBA terminalfor every SHAP score computed. If you are calculating the shap scores for 200 frames, you can expect the beginning of the calculations may look something like this in the main SimBA terminal:

<p align="center">
<img src="https://github.com/sgoldenlab/simba/blob/master/images/SHAP3.png" />
</p>

>**Note**: As noted above, calculating SHAP scores is computationally expensive and depending on the number of frames you entered in the `# target present` and `# target absent`, this could take a while. If you are calculating SHAP scores on a lot of frames, it's best to make it a night job.

Once complete, you will see the following message `All SHAP data saved in project_folder/models/evaluations directory`. Navigate to the directory to access your SHAP values. In this folder you will see two seperate CSV files. For example, if you generated SHAP values for a classifier called `copulation`, you will find the files `RAW_SHAP_feature_values_copulation_prediction.csv` and `SHAP_values_copulation_prediction.csv`. Below we will go through what the data in these two files mean. 


### Step 3: Interpreting the SHAp value ouput generated by SimBA

The two SHAP value output files have an equal number of rows, where every row represent a frame. If you choose to generate SHAP values for 200 frames, for example, each of the two files will contain 200 rows, where row *N* within both files represent the data for the **same frame**. The first file (`SHAP_values_copulation_prediction.csv`) contains the actual SHAP values. The second file (`RAW_SHAP_feature_values_copulation_prediction.csv`) contain the **raw** feature values for the same frames. The reason for generating two files is that it is sometimes necessery to match the SHAP values (represented in the `SHAP_values_copulation_prediction.csv`) with an actual feature value (represented in the `RAW_SHAP_feature_values_copulation_prediction.csv`).  

<p align="center">
<img src="https://github.com/sgoldenlab/simba/blob/master/images/SHAP4.png" />
</p>

To help understand this, I've libed the two CSV files next to each other in this image, with the `SHAP values` shown on the left, and the `RAW feature values` on the right.





