# Calculating feature SHAP values in SimBA

An understanding, and abibility to explain, how and why machine learning models reach their decisions (*i.e., *why* does my classifier think these specific frames are attack events?) is important not only for the scientific method but will help you compare the similarities and differences of classifiers generated by different annotators and institutions.  
